{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Packages"
      ],
      "metadata": {
        "id": "_bzRZA8jATUy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCiwjTTeADjb"
      },
      "outputs": [],
      "source": [
        "from TwitterAPI import TwitterAPI\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Twitter API"
      ],
      "metadata": {
        "id": "it_eFsGuAmP-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LM192zHnADjf"
      },
      "outputs": [],
      "source": [
        "consumer_key = 'StFnoZ0aLRsGBfdXKsvgixh2G'\n",
        "consumer_secret = 'DXAzF6aSRrbmiJ1cDk0N9NllpRqsZsCcd5SWsj0bSVsKzoFUCR'\n",
        "\n",
        "access_token_key = '1013584071589588992-S5tkore4k0a033GoToVVqZBsN8awRR'\n",
        "access_token_secret = '4IGXFqW6V0TPIbSy73QffNKhtscbv7p8HmYBvzKeD1gcN'\n",
        "\n",
        "api = TwitterAPI(consumer_key, consumer_secret, access_token_key, access_token_secret)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Request data from Twitter API"
      ],
      "metadata": {
        "id": "0sqlwwyGAuiQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gtp6Xc9vADjj"
      },
      "outputs": [],
      "source": [
        "def get_df_from_tweets(r):\n",
        "    '''\n",
        "    Converts the response from TwitterAPI into a Pandas dataframe.\n",
        "            Parameters:\n",
        "                    r (TwitterResponse): The response object after calling the request method from the TwitterAPI.\n",
        "            Returns:\n",
        "                    df (DataFrame): A pandas dataframe containing the data.\n",
        "    '''\n",
        "    data_dict = r.json()['results']\n",
        "    df = pd.read_json(json.dumps(data_dict), orient='records')\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_df_from_search(params):\n",
        "    '''\n",
        "    Sends the query to the Twitter Premium Search API.\n",
        "            Parameters:\n",
        "                    params (dict): A dictionary of parameters for the Twitter search API.\n",
        "                                   See this page for the possible query parameters: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/guides/premium-operators\n",
        "            Returns:\n",
        "                    df (DataFrame): A pandas dataframe containing the data.\n",
        "                    next_ (str): The next token to get the next page of results from the Twitter search API. \n",
        "                                 Read about pagination here: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/premium-search\n",
        "    '''\n",
        "    PRODUCT = '30day'\n",
        "    LABEL = 'justintodata'\n",
        "    r = api.request('tweets/search/{}/:{}'.format(PRODUCT, LABEL), params)\n",
        "    print(r.status_code)\n",
        "    print(r.get_quota())\n",
        "    next_ = r.json().get('next')\n",
        "    return get_df_from_tweets(r), next_\n",
        "\n",
        "\n",
        "def get_data(search_term, api, max_queries=5):\n",
        "    '''\n",
        "    Retrieves multiple pages of tweets with the specified search term.\n",
        "            Parameters:\n",
        "                    search_term (str): The string to search in the tweet.\n",
        "                    api (TwitterAPI): The TwitterAPI object.\n",
        "                    max_queries: The maximum number of queries (pages) to retrieve.\n",
        "            Returns:\n",
        "                    (DataFrame): A pandas dataframe containing the data.\n",
        "    '''\n",
        "    delay_seconds = 2\n",
        "    df_list = []\n",
        "    \n",
        "    # query the search term. The higher maxResults you can put is 100 for our twitter account.\n",
        "    params = {'query':search_term, 'maxResults': 100}\n",
        "    df, next_ = get_df_from_search(params)\n",
        "    df_list.append(df)\n",
        "    time.sleep(delay_seconds)\n",
        "    \n",
        "    # use the next token to get the next page of tweets if we want more than 100.\n",
        "    num_queries_remaining = max_queries - 1\n",
        "    while num_queries_remaining > 0 and next_:\n",
        "        params['next'] = next_\n",
        "        df, next_ = get_df_from_search(params)\n",
        "        df_list.append(df)\n",
        "        num_queries_remaining -= 1\n",
        "        time.sleep(delay_seconds)  # must delay the search or else Twitter will say we're sending too many requests.\n",
        "        \n",
        "    return pd.concat(df_list).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data for keyword.\n",
        "df_twitterkeyword = get_data('@putin', api, max_queries=30)"
      ],
      "metadata": {
        "id": "J7kQDKWgCOfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process the data and Apply the TextBlob model"
      ],
      "metadata": {
        "id": "LZgrLz7PC4dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The column user is in dictionary format. This function unpacks it into 4 separate columns.\n",
        "def flatten_user_info(df):\n",
        "    def unpack_user(d):\n",
        "        return d.get('id'), d.get('name'), d.get('screen_name'), d.get('location')\n",
        "    return pd.DataFrame(df['user'].map(unpack_user).to_list(), index=df.index)\n",
        "\n",
        "\n",
        "def get_full_text(df):\n",
        "    def unpack_extended_tweet(d):\n",
        "        if not isinstance(d,dict):\n",
        "            return None\n",
        "        return d.get('full_text')    \n",
        "    \n",
        "    return df['extended_tweet'].map(unpack_extended_tweet)\n",
        "\n",
        "def get_sentiment(df, txt_col):\n",
        "    return df[txt_col].map(lambda txt: TextBlob(txt).sentiment.polarity)\n",
        "\n",
        "\n",
        "def prepare_data(df):\n",
        "    # filter out retweets. We're only interested in the originals.\n",
        "    msk = (~df['text'].str.startswith('RT'))\n",
        "    df_filtered = df[msk].copy()\n",
        "    \n",
        "    # get the user information in separate columns.\n",
        "    df_filtered[['user_id', 'username', 'user_screen_name', 'user_location']] = flatten_user_info(df_filtered)\n",
        "    \n",
        "    # get the full_text if it exists. Otherwise fill it in with the text.\n",
        "    df_filtered['full_text'] = get_full_text(df_filtered)\n",
        "    msk = df_filtered['full_text'].isnull()\n",
        "    df_filtered.loc[msk, 'full_text'] = df_filtered.loc[msk, 'text']\n",
        "    \n",
        "    # get the sentiment of the full_text.\n",
        "    df_filtered['textblob_sentiment'] = get_sentiment(df_filtered, 'full_text')\n",
        "    return df_filtered\n",
        "    "
      ],
      "metadata": {
        "id": "tW3bSpWGC6av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_twitterkeyword = prepare_data(df_twitterkeyword)\n",
        "\n",
        "df_twitterkeyword.info()\n",
        "\n",
        "df_twitterkeyword.head()"
      ],
      "metadata": {
        "id": "-8Y9DkL9DJhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label a sample manually"
      ],
      "metadata": {
        "id": "SK0NS4rHIZAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_twitterkeyword.sample(n=100).to_csv('twitter-data.csv', index=False)\n",
        "\n",
        "df_labelled = pd.read_csv('twitter-data-labeled.csv')\n",
        "\n",
        "df_labelled.head(10)"
      ],
      "metadata": {
        "id": "i5s3m60DIjW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "df_labelled[['is_neg', 'is_neutral', 'is_pos']] = pd.DataFrame(label_binarize(df_labelled['label'], [-1, 0, 1]), index=df_labelled.index)\n",
        "\n",
        "df_labelled.head(10)\n",
        "\n",
        "df_labelled['is_neg'].value_counts(dropna=False)\n",
        "\n",
        "df_labelled['is_pos'].value_counts(dropna=False)\n",
        "\n",
        "df_labelled['is_neutral'].value_counts(dropna=False)"
      ],
      "metadata": {
        "id": "OQp3CnfUJ48y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the sentiment analysis results"
      ],
      "metadata": {
        "id": "UDsTOohgKCDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IEMfhJCYKe-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function is based off of this example: \n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py\n",
        "def plot_roc_curve(fpr, tpr, roc_auc):\n",
        "    plt.figure()\n",
        "    lw = 2\n",
        "    plt.plot(fpr, tpr, color='darkorange',\n",
        "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hh8cS47gKtw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Negative Tweets"
      ],
      "metadata": {
        "id": "Z5RWuR2tK2e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_fpr, neg_tpr, neg_thresholds = roc_curve(df_labelled['is_neg'], -df_labelled['textblob_sentiment'], pos_label=1)\n",
        "neg_roc_auc = auc(neg_fpr, neg_tpr)\n",
        "\n",
        "plot_roc_curve(neg_fpr, neg_tpr, neg_roc_auc)"
      ],
      "metadata": {
        "id": "2EEzTriXLDzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, t in enumerate(neg_thresholds):\n",
        "    neg_pred = -df_labelled['textblob_sentiment'] > t\n",
        "    acc = accuracy_score(df_labelled['is_neg'], neg_pred)\n",
        "    print('threshold: {}, accuracy: {}'.format(-t, acc))"
      ],
      "metadata": {
        "id": "lx_zILV5LdnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positive Tweets"
      ],
      "metadata": {
        "id": "j3wVX5WkLh5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_fpr, pos_tpr, pos_thresholds = roc_curve(df_labelled['is_pos'], df_labelled['textblob_sentiment'], pos_label=1)\n",
        "pos_roc_auc = auc(pos_fpr, pos_tpr)\n",
        "\n",
        "plot_roc_curve(pos_fpr, pos_tpr, pos_roc_auc)"
      ],
      "metadata": {
        "id": "6mV1goeoLj9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, t in enumerate(pos_thresholds):\n",
        "    pos_pred = df_labelled['textblob_sentiment'] > t\n",
        "    acc = accuracy_score(df_labelled['is_pos'], pos_pred)\n",
        "    print('threshold: {}, accuracy: {}'.format(t, acc))"
      ],
      "metadata": {
        "id": "DV8Oz3HBLxzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_twitterkeyword['predicted_sentiment'] = pd.cut(df_twitterkeyword['textblob_sentiment'],\n",
        "                                             bins=[-2, -0.05, 0.2857, 2], \n",
        "                                             labels=['negative', 'neutral', 'positive'], \n",
        "                                             right=False)"
      ],
      "metadata": {
        "id": "n4LoGFYBL5zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_twitterkeyword[['full_text', 'textblob_sentiment', 'predicted_sentiment']].sample(n=10)"
      ],
      "metadata": {
        "id": "cTFoWhN-MDQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the results"
      ],
      "metadata": {
        "id": "Lg3-0hiTMJ_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_twitterkeyword['created_at_hour'] = df_twitterkeyword['created_at'].dt.round('H')\n",
        "\n",
        "aggregation = {'cnt': ('id', 'count')}\n",
        "df_sentiment_by_time = df_twitterkeyword.groupby(['created_at_hour', 'predicted_sentiment']).agg(**aggregation).reset_index()\n",
        "\n",
        "df_sentiment_by_time"
      ],
      "metadata": {
        "id": "cj1FEP6CMLbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.line(df_sentiment_by_time, x=\"created_at_hour\", y=\"cnt\", color=\"predicted_sentiment\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "CFlvXSYHMrc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordCloud"
      ],
      "metadata": {
        "id": "P3dN1kZnMvdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure"
      ],
      "metadata": {
        "id": "-xgKjFO6M2RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords do not appear in the wordcloud.\n",
        "stopwords = STOPWORDS.copy()\n",
        "stopwords.update(['http', 'https', 'co', 'starbuck', 'starbucks']) # add some additional stopwords.\n",
        "\n",
        "# make all the text lowercase and combine everything together.\n",
        "all_txt = [txt.lower() for txt in df_starbucks['full_text'].to_list()]\n",
        "all_txt = ' '.join(all_txt)\n",
        "\n",
        "# create and plot the wordcloud.\n",
        "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\", width=800, height=600).generate(all_txt)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cm4cV-ZoNF59"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}